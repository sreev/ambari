<!--

 Licensed to the Apache Software Foundation (ASF) under one
 or more contributor license agreements.  See the NOTICE file
 distributed with this work for additional information
 regarding copyright ownership.  The ASF licenses this file
 to you under the Apache License, Version 2.0 (the
 "License"); you may not use this file except in compliance
 with the License.  You may obtain a copy of the License at

     http://www.apache.org/licenses/LICENSE-2.0

 Unless required by applicable law or agreed to in writing, software
 distributed under the License is distributed on an "AS IS" BASIS,
 WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
 See the License for the specific language governing permissions and
 limitations under the License.

-->

<applicationDocs targetNamespace="http://research.sun.com/wadl/2006/10">

<doc xml:lang="en" title="Ambari REST API">

<p>
   Ambari provides rich REST interfaces that allow the creation, 
   modification, querying, and deletion of stacks and clusters. The
   primary resources are: 
   <ul>
   <li><a href="index.html#Stacks">Stacks</a> - definition of which 
       components should be deployed and how they should be 
       <a href="index.html#Configuration">configured</a>.</li>
   <li><a href="index.html#Clusters">Clusters</a> - combination a stack 
       and nodes to run Hadoop</li><li>Nodes - the machines managed by 
       Ambari</li>
   </ul>
   Each is represented by a top level resource, which is a container,
   and nested resources for each instance.
</p><br/>
<p>
   The resources and the entities that are passed to them are defined
   using JAXB and are represented in either XML or JSON formats
   depending on the ContentType and Accept HTTP headers. The definition
   of the types is given in the <a
   href="apidocs/org/apache/ambari/common/rest/entities/package-summary.html">
   JavaDoc</a>.
</p><br/>
<p>
   Typical usage would be to create a new stack derived from a pre-defined
   one and change the neccessary configuration parameters. Then create a
   cluster based on the stack by assigning nodes and marking it active.
</p>
</doc>

</applicationDocs>
